---
title: "Interactive Tool to Identify and Understand Biases and Stereotypes in Large Language Models."
date: 2023-08-01
url: /d2/
author: "Samia Kabir Â· Purdue University"
description: ""
image: "/stile_mini.png"
summary: "In this project, we developed an interactive tool to identify biases and stereotypes in pre-trained word embeddings. Apart from identifying biases, this tool also gives users the flexibility to go back to the source of biases in the training data and interactively debug the source of biases. "
cover:
    image: "/stile_mini.png"
    alt: "overview diagram"
    relative: false
editPost:
    URL: "https://www.youtube.com/watch?v=6e60Id_XQMM"
    Text: "Demonstration of Stile"
showToc: true
disableAnchoredHeadings: false
hideSummary: false
weight: 3



---

## Overview

NLP's recent success depends on pre-trained text representation such as word embeddings, but they can carry social biases like gender stereotypes. Current bias detection tools are limited and lack user interaction. We introduce Stile, an interactive system for identifying and understanding biases in pre-trained word embeddings. This tool provides an overview of biases using a compact visualization and lets you explore the training data to understand the bias origins.

![alt text](/stile.png)


---

---

## Download

- [Full paper (CHI'24)](https://dl.acm.org/doi/pdf/10.1145/3613904.3642111)
- [GitHub repository](https://github.com/SamiaKabir/Interactive-Bias-Debug-and-Visualization)
- [Supplemental Materials](https://dl.acm.org/doi/full/10.1145/3613904.3642111#sec-supp)
